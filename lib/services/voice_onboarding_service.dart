import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:permission_handler/permission_handler.dart';
import '../services/unified_hordvoice_service.dart';
import '../services/voice_management_service.dart';
import '../services/azure_speech_service.dart';

/// √âtape 5: Service d'onboarding vocal complet avec support spatial
class VoiceOnboardingService {
  static final VoiceOnboardingService _instance =
      VoiceOnboardingService._internal();
  factory VoiceOnboardingService() => _instance;
  VoiceOnboardingService._internal();

  late UnifiedHordVoiceService _unifiedService;
  late VoiceManagementService _voiceService;
  late AzureSpeechService _speechService;

  bool _isInitialized = false;
  String _currentStep = 'welcome';
  Map<String, dynamic> _onboardingData = {};

  // Compteurs pour retry et timeouts
  int _micPermissionRetries = 0;
  int _voiceSelectionRetries = 0;
  final int _maxRetries = 3;

  // Support spatial
  bool _spatialModeEnabled = false;
  Function(String)? _spatialFeedbackCallback;

  Future<void> initialize() async {
    if (_isInitialized) return;

    try {
      _unifiedService = UnifiedHordVoiceService();
      _voiceService = VoiceManagementService();
      _speechService = AzureSpeechService();

      // UnifiedHordVoiceService est un singleton d√©j√† initialis√© - √©viter la boucle infinie
      debugPrint('Service unifi√© r√©cup√©r√© depuis le singleton');

      await _voiceService.initialize().catchError((e) {
        debugPrint('Service vocal non disponible (continuer): $e');
      });

      await _speechService.initialize().catchError((e) {
        debugPrint('Service speech non disponible (continuer): $e');
      });

      _isInitialized = true;
      debugPrint('VoiceOnboardingService initialis√© (mode graceful)');
    } catch (e) {
      debugPrint('Erreur initialisation VoiceOnboardingService: $e');
      // Ne pas lancer d'exception - continuer en mode d√©grad√©
      _isInitialized = true;
    }
  }

  /// √âtape 5A: D√©marrage auto - Greeting imm√©diat avec attente utilisateur
  Future<void> startOnboarding() async {
    if (!_isInitialized) {
      await initialize();
    }

    debugPrint('üéôÔ∏è D√©marrage onboarding vocal s√©quentiel');

    try {
      // Arr√™ter toute √©coute active pour √©viter les conflits
      await _stopAllListeningServices();
      
      final isFirstRun = await _isFirstRun();

      if (isFirstRun) {
        await _stepWelcomeFirstTime();
      } else {
        await _stepWelcomeReturning();
      }
    } catch (e) {
      debugPrint('Erreur d√©marrage onboarding: $e');
      // Fallback graceful
      try {
        await _unifiedService
            .speakText('Bienvenue dans HordVoice. Configuration en cours.')
            .catchError((e) {
              debugPrint('TTS non disponible: $e');
            });
      } catch (fallbackError) {
        debugPrint('Fallback TTS √©chou√©: $fallbackError');
      }

      // Marquer comme termin√© pour √©viter les boucles d'erreur
      await _markOnboardingCompleted();
    }
  }

  /// Arr√™ter tous les services d'√©coute pour √©viter les conflits
  Future<void> _stopAllListeningServices() async {
    try {
      // Arr√™ter √©coute Azure Speech si active
      if (_speechService.isListening) {
        await _speechService.stopListening();
      }
      
      // Arr√™ter wake word detection si m√©thode existe
      try {
        await _unifiedService.stopWakeWordDetection();
      } catch (e) {
        debugPrint('Wake word detection non disponible: $e');
      }
      
      debugPrint('‚úÖ Services d\'√©coute arr√™t√©s pour onboarding');
    } catch (e) {
      debugPrint('Erreur arr√™t services √©coute: $e');
    }
  }

  /// Attendre la confirmation de l'utilisateur avant de continuer
  Future<void> _waitForUserConfirmation(String expectedKeywords) async {
    debugPrint('üéß Attente confirmation utilisateur: $expectedKeywords');
    
    try {
      // D√©marrer √©coute sp√©cifiquement pour cette confirmation
      await _speechService.startListening();
      
      bool confirmationReceived = false;
      
      // Timeout apr√®s 15 secondes
      Timer? timeoutTimer = Timer(Duration(seconds: 15), () async {
        if (!confirmationReceived) {
          await _speechService.stopListening();
          await _handleConfirmationTimeout();
        }
      });

      // √âcouter la r√©ponse
      _speechService.resultStream.listen((result) async {
        if (result.isFinal && !confirmationReceived) {
          confirmationReceived = true;
          timeoutTimer.cancel();
          await _speechService.stopListening();
          
          final text = result.recognizedText.toLowerCase();
          debugPrint('üé§ R√©ponse utilisateur: $text');
          
          // V√©rifier si la r√©ponse contient les mots-cl√©s attendus
          if (text.contains('continuer') || 
              text.contains('oui') || 
              text.contains('ok') ||
              text.contains('d\'accord') ||
              text.contains('commencer')) {
            debugPrint('‚úÖ Confirmation positive re√ßue');
            await _unifiedService.speakText('Parfait ! Continuons.');
          } else if (text.contains('non') || text.contains('arr√™ter')) {
            debugPrint('‚ùå Confirmation n√©gative re√ßue');
            await _unifiedService.speakText('D\'accord, nous arr√™tons ici.');
            await _markOnboardingCompleted(); // Arr√™ter l'onboarding
            return;
          } else {
            debugPrint('‚ùì R√©ponse ambigu√´, on continue quand m√™me');
            await _unifiedService.speakText('Je n\'ai pas bien compris, mais continuons.');
          }
          
          // Petite pause avant l'√©tape suivante
          await Future.delayed(Duration(seconds: 1));
        }
      });

      // G√©rer les erreurs de reconnaissance
      _speechService.errorStream.listen((error) async {
        if (!confirmationReceived) {
          confirmationReceived = true;
          timeoutTimer.cancel();
          await _speechService.stopListening();
          await _handleConfirmationError();
        }
      });
      
    } catch (e) {
      debugPrint('Erreur attente confirmation: $e');
      // Continuer quand m√™me en cas d'erreur
      await _unifiedService.speakText('Je continue la configuration.');
    }
  }

  /// G√©rer le timeout de confirmation
  Future<void> _handleConfirmationTimeout() async {
    debugPrint('‚è∞ Timeout confirmation utilisateur');
    await _unifiedService.speakText(
      'Je n\'ai pas entendu de r√©ponse. Je continue la configuration.',
    );
  }

  /// G√©rer les erreurs de confirmation
  Future<void> _handleConfirmationError() async {
    debugPrint('‚ùå Erreur confirmation utilisateur');
    await _unifiedService.speakText(
      'Il y a eu un petit probl√®me d\'√©coute. Je continue quand m√™me.',
    );
  }

  /// V√©rifier si c'est le premier lancement
  Future<bool> _isFirstRun() async {
    final prefs = await SharedPreferences.getInstance();
    return !(prefs.getBool('onboarding_completed') ?? false);
  }

  /// √âtape 5A: Greeting pour premi√®re fois - AVEC ATTENTE
  Future<void> _stepWelcomeFirstTime() async {
    _currentStep = 'welcome_first';

    debugPrint('üó£Ô∏è √âtape 1: Message d\'accueil');
    
    // Message d'accueil - ATTENDRE la fin compl√®te
    await _unifiedService.speakText(
      'Bonjour ! Je suis Ric, votre assistant vocal personnel. '
      'Je vais vous guider pour me configurer en quelques √©tapes. '
      'Tout se fait √† la voix, pas besoin de touches.',
    );

    // ATTENDRE 3 secondes pour que l'utilisateur comprenne
    debugPrint('‚è≥ Attente assimilation message...');
    await Future.delayed(Duration(seconds: 3));
    
    // Demander confirmation avant de continuer
    await _unifiedService.speakText(
      'Dites "continuer" ou "oui" quand vous √™tes pr√™t pour commencer la configuration.',
    );
    
    // ATTENDRE la r√©ponse de l'utilisateur
    await _waitForUserConfirmation('continuer');
    
    debugPrint('‚úÖ Utilisateur pr√™t, passage √† l\'√©tape microphone');
    await _stepCheckMicrophone();
  }

  /// Greeting pour utilisateur qui revient - AVEC ACTIVATION WAKE WORD
  Future<void> _stepWelcomeReturning() async {
    _currentStep = 'welcome_returning';

    final now = DateTime.now();
    String greeting;

    if (now.hour < 12) {
      greeting =
          'Bonjour ! Ric √† votre service. Dites "Hey Ric" pour commencer.';
    } else if (now.hour < 18) {
      greeting =
          'Bel apr√®s-midi ! Je suis pr√™t. Dites "Hey Ric" quand vous voulez.';
    } else {
      greeting = 'Bonsoir ! Ric est l√†. R√©veillez-moi avec "Hey Ric".';
    }

    debugPrint('üó£Ô∏è Message d\'accueil utilisateur revenant');
    await _unifiedService.speakText(greeting);

    // ATTENDRE la fin du TTS
    await Future.delayed(Duration(seconds: 2));
    
    // ACTIVER le wake word detection apr√®s le message
    debugPrint('üéß Activation d√©tection wake word "Hey Ric"');
    try {
      await _unifiedService.startWakeWordDetection();
      debugPrint('‚úÖ Wake word "Hey Ric" activ√©');
    } catch (e) {
      debugPrint('‚ùå Erreur activation wake word: $e');
      // Fallback : √©coute continue
      await _unifiedService.speakText(
        'Vous pouvez maintenant me parler directement sans appuyer sur un bouton.',
      );
    }

    // Marquer l'onboarding comme termin√© pour les prochaines fois
    await _markOnboardingCompleted();
  }

  /// √âtape 5A: V√©rification microphone avec rationale vocal
  Future<void> _stepCheckMicrophone() async {
    _currentStep = 'microphone_check';

    final micStatus = await Permission.microphone.status;

    if (micStatus.isGranted) {
      await _unifiedService.speakText(
        'Parfait, le microphone est autoris√©. Continuons.',
      );
      await Future.delayed(Duration(seconds: 1));
      await _stepVoiceSelection();
      return;
    }

    // Rationale vocal avant demande permission
    await _unifiedService.speakText(
      'Pour m\'√©couter et ex√©cuter vos commandes √† la voix, j\'ai besoin d\'acc√©der au microphone. '
      'Dites "oui" pour autoriser maintenant, ou "non" si vous pr√©f√©rez configurer manuellement.',
    );

    await _listenForMicrophonePermission();
  }

  /// √âcouter r√©ponse permission microphone
  Future<void> _listenForMicrophonePermission() async {
    try {
      await _speechService.startListening();

      // Timeout apr√®s 10 secondes
      Timer? timeoutTimer = Timer(Duration(seconds: 10), () async {
        await _speechService.stopListening();
        await _handleMicrophoneTimeout();
      });

      // √âcouter r√©sultat
      _speechService.resultStream.listen((result) async {
        if (result.isFinal) {
          timeoutTimer.cancel();
          await _speechService.stopListening();
          await _processMicrophoneResponse(result.recognizedText);
        }
      });

      // √âcouter erreurs
      _speechService.errorStream.listen((error) async {
        timeoutTimer.cancel();
        debugPrint('Erreur STT permission micro: ${error.errorMessage}');
        await _handleMicrophoneError();
      });
    } catch (e) {
      debugPrint('Erreur √©coute permission micro: $e');
      await _handleMicrophoneError();
    }
  }

  /// Traiter r√©ponse permission microphone
  Future<void> _processMicrophoneResponse(String response) async {
    final lowerResponse = response.toLowerCase();

    if (lowerResponse.contains(
      RegExp(r'\b(oui|ok|accord|autoriser?|accepte?r?)\b'),
    )) {
      await _requestMicrophonePermission();
    } else if (lowerResponse.contains(
      RegExp(r'\b(non|pas|refus[ez]?|jamais)\b'),
    )) {
      await _handleMicrophoneRefused();
    } else {
      // R√©ponse non comprise
      _micPermissionRetries++;
      if (_micPermissionRetries < _maxRetries) {
        await _unifiedService.speakText(
          'D√©sol√©, je n\'ai pas compris. Dites "oui" pour autoriser ou "non" pour refuser.',
        );
        await _listenForMicrophonePermission();
      } else {
        await _handleMicrophoneTimeout();
      }
    }
  }

  /// Demander permission microphone syst√®me
  Future<void> _requestMicrophonePermission() async {
    try {
      await _unifiedService.speakText(
        'Je lance la demande d\'autorisation. Veuillez accepter dans la popup.',
      );

      final permission = await Permission.microphone.request();

      if (permission.isGranted) {
        await _unifiedService.speakText(
          'Merci ! Microphone activ√©. Continuons avec le choix de votre voix.',
        );
        await Future.delayed(Duration(seconds: 1));
        await _stepVoiceSelection();
      } else if (permission.isDenied) {
        await _handleMicrophoneRefused();
      } else if (permission.isPermanentlyDenied) {
        await _handleMicrophonePermanentlyDenied();
      }
    } catch (e) {
      debugPrint('Erreur demande permission: $e');
      await _handleMicrophoneError();
    }
  }

  /// G√©rer refus permission microphone
  Future<void> _handleMicrophoneRefused() async {
    await _unifiedService.speakText(
      'D\'accord. Sans microphone, je ne pourrai pas √©couter automatiquement. '
      'Vous pouvez l\'autoriser plus tard dans les param√®tres de l\'application. '
      'Veux-tu que je t\'explique comment faire ?',
    );

    // Pour l'instant, continuer l'onboarding sans micro
    await Future.delayed(Duration(seconds: 3));
    await _stepVoiceSelection();
  }

  /// G√©rer permission microphone bloqu√©e d√©finitivement
  Future<void> _handleMicrophonePermanentlyDenied() async {
    await _unifiedService.speakText(
      'Permission microphone bloqu√©e. Pour m\'utiliser, veuillez aller dans Param√®tres > Applications > HordVoice > Autorisations et activer le microphone. '
      'Je continue la configuration en attendant.',
    );

    await Future.delayed(Duration(seconds: 3));
    await _stepVoiceSelection();
  }

  /// G√©rer timeout ou erreur microphone
  Future<void> _handleMicrophoneTimeout() async {
    await _unifiedService.speakText(
      'Je n\'ai pas entendu de r√©ponse. Je continue avec la configuration. '
      'Vous pourrez autoriser le microphone plus tard.',
    );

    await Future.delayed(Duration(seconds: 2));
    await _stepVoiceSelection();
  }

  /// G√©rer erreur microphone
  Future<void> _handleMicrophoneError() async {
    await _unifiedService.speakText(
      'Probl√®me technique avec le microphone. Continuons la configuration. '
      'Vous pourrez configurer l\'audio plus tard.',
    );

    await Future.delayed(Duration(seconds: 2));
    await _stepVoiceSelection();
  }

  /// √âtape 5B: Choix de voix voice-only
  Future<void> _stepVoiceSelection() async {
    _currentStep = 'voice_selection';

    await _unifiedService.speakText('Maintenant, choisissons ma voix.');
    await Future.delayed(Duration(seconds: 1));

    // G√©n√©rer liste vocale
    final voiceListResponse = _voiceService.generateVoiceListResponse();
    await _unifiedService.speakText(voiceListResponse);

    await _listenForVoiceSelection();
  }

  /// √âcouter s√©lection de voix
  Future<void> _listenForVoiceSelection() async {
    try {
      await _speechService.startListening();

      Timer? timeoutTimer = Timer(Duration(seconds: 15), () async {
        await _speechService.stopListening();
        await _handleVoiceSelectionTimeout();
      });

      _speechService.resultStream.listen((result) async {
        if (result.isFinal) {
          timeoutTimer.cancel();
          await _speechService.stopListening();
          await _processVoiceSelection(result.recognizedText);
        }
      });

      _speechService.errorStream.listen((error) async {
        timeoutTimer.cancel();
        await _handleVoiceSelectionError();
      });
    } catch (e) {
      await _handleVoiceSelectionError();
    }
  }

  /// Traiter s√©lection de voix
  Future<void> _processVoiceSelection(String response) async {
    final result = await _voiceService.selectVoiceByName(response);

    if (!result.contains('D√©sol√©')) {
      // Succ√®s - jouer aper√ßu dans nouvelle voix
      await _unifiedService.speakText(result);

      final selectedVoice = _voiceService.selectedVoice;
      if (selectedVoice != null) {
        final preview = await _voiceService.generateVoicePreview(selectedVoice);
        await _unifiedService.speakText(preview);
      }

      await Future.delayed(Duration(seconds: 2));
      await _stepPersonalitySelection();
    } else {
      // √âchec
      _voiceSelectionRetries++;
      if (_voiceSelectionRetries < _maxRetries) {
        await _unifiedService.speakText(result);
        await _listenForVoiceSelection();
      } else {
        await _useDefaultVoice();
      }
    }
  }

  /// Utiliser voix par d√©faut
  Future<void> _useDefaultVoice() async {
    await _unifiedService.speakText(
      'Aucun probl√®me, je garde ma voix par d√©faut. Vous pourrez la changer plus tard en disant "quelles voix".',
    );

    await Future.delayed(Duration(seconds: 2));
    await _stepPersonalitySelection();
  }

  /// G√©rer timeout s√©lection voix
  Future<void> _handleVoiceSelectionTimeout() async {
    await _unifiedService.speakText(
      'Pas de r√©ponse. Je garde ma voix actuelle. Dites "quelles voix" plus tard pour changer.',
    );

    await Future.delayed(Duration(seconds: 2));
    await _stepPersonalitySelection();
  }

  /// G√©rer erreur s√©lection voix
  Future<void> _handleVoiceSelectionError() async {
    await _unifiedService.speakText(
      'Probl√®me technique. Je garde ma voix par d√©faut. Continuons.',
    );

    await Future.delayed(Duration(seconds: 1));
    await _stepPersonalitySelection();
  }

  /// √âtape 5C: Choix personnalit√© IA voice-only
  Future<void> _stepPersonalitySelection() async {
    _currentStep = 'personality_selection';

    await _unifiedService.speakText(
      'Maintenant, choisissez mon style de conversation. '
      'Dites "style m√®re" pour une approche bienveillante et protectrice, '
      '"style ami" pour un ton d√©contract√© et complice, '
      'ou "style assistant" pour un comportement professionnel.',
    );

    await _listenForPersonalitySelection();
  }

  /// √âcouter s√©lection personnalit√©
  Future<void> _listenForPersonalitySelection() async {
    try {
      await _speechService.startListening();

      Timer? timeoutTimer = Timer(Duration(seconds: 12), () async {
        await _speechService.stopListening();
        await _useDefaultPersonality();
      });

      _speechService.resultStream.listen((result) async {
        if (result.isFinal) {
          timeoutTimer.cancel();
          await _speechService.stopListening();
          await _processPersonalitySelection(result.recognizedText);
        }
      });
    } catch (e) {
      await _useDefaultPersonality();
    }
  }

  /// Traiter s√©lection personnalit√©
  Future<void> _processPersonalitySelection(String response) async {
    final lowerResponse = response.toLowerCase();
    String personality = 'ami'; // d√©faut
    String confirmationText = '';

    if (lowerResponse.contains('m√®re') || lowerResponse.contains('maman')) {
      personality = 'mere_africaine';
      confirmationText =
          'Style maternel activ√©. Je serai bienveillante et protectrice avec vous.';
    } else if (lowerResponse.contains('ami') ||
        lowerResponse.contains('complice')) {
      personality = 'ami';
      confirmationText = 'Style ami activ√©. On va bien s\'entendre !';
    } else if (lowerResponse.contains('assistant') ||
        lowerResponse.contains('professionnel')) {
      personality = 'assistant_pro';
      confirmationText =
          'Style professionnel activ√©. Je serai efficace et pr√©cise.';
    } else {
      // Pas compris - utiliser ami par d√©faut
      confirmationText =
          'Je n\'ai pas bien compris. J\'adopte un style amical par d√©faut.';
    }

    // Sauvegarder choix
    _onboardingData['personality'] = personality;
    await _savePersonalityChoice(personality);

    await _unifiedService.speakText(confirmationText);
    await Future.delayed(Duration(seconds: 2));
    await _stepFinalTest();
  }

  /// Utiliser personnalit√© par d√©faut
  Future<void> _useDefaultPersonality() async {
    _onboardingData['personality'] = 'ami';
    await _savePersonalityChoice('ami');

    await _unifiedService.speakText(
      'Aucune r√©ponse. J\'adopte un style amical par d√©faut. Vous pourrez le changer plus tard.',
    );

    await Future.delayed(Duration(seconds: 2));
    await _stepFinalTest();
  }

  /// √âtape 5D: Test interactif final
  Future<void> _stepFinalTest() async {
    _currentStep = 'final_test';

    await _unifiedService.speakText(
      'Parfait ! Configuration termin√©e. Faisons un test rapide. '
      'Dites "Bonjour Ric" pour voir comment je r√©agis.',
    );

    await _listenForFinalTest();
  }

  /// √âcouter test final
  Future<void> _listenForFinalTest() async {
    try {
      await _speechService.startListening();

      Timer? timeoutTimer = Timer(Duration(seconds: 8), () async {
        await _speechService.stopListening();
        await _completeOnboardingWithoutTest();
      });

      _speechService.resultStream.listen((result) async {
        if (result.isFinal) {
          timeoutTimer.cancel();
          await _speechService.stopListening();
          await _processFinalTest(result.recognizedText);
        }
      });
    } catch (e) {
      await _completeOnboardingWithoutTest();
    }
  }

  /// Traiter test final
  Future<void> _processFinalTest(String response) async {
    // Simuler r√©ponse interactive bas√©e sur personnalit√©
    final personality = _onboardingData['personality'] ?? 'ami';
    String testResponse = '';

    switch (personality) {
      case 'mere_africaine':
        testResponse =
            'Bonjour mon enfant ! Je suis l√† pour veiller sur vous. Comment allez-vous aujourd\'hui ?';
        break;
      case 'assistant_pro':
        testResponse =
            'Bonjour. Je suis op√©rationnelle et pr√™te √† vous assister. Que puis-je faire pour vous ?';
        break;
      default: // ami
        testResponse =
            'Salut ! Content de te parler ! Alors, qu\'est-ce qu\'on fait ensemble aujourd\'hui ?';
    }

    await _unifiedService.speakText(testResponse);
    await Future.delayed(Duration(seconds: 3));
    await _completeOnboardingSuccessfully();
  }

  /// Finaliser onboarding sans test
  Future<void> _completeOnboardingWithoutTest() async {
    await _unifiedService.speakText(
      'Aucun probl√®me ! Configuration termin√©e. Je suis maintenant pr√™t √† vous assister. '
      'Dites "Hey Ric" pour me r√©veiller √† tout moment.',
    );

    await _markOnboardingCompleted();
  }

  /// Finaliser onboarding avec succ√®s
  Future<void> _completeOnboardingSuccessfully() async {
    await _unifiedService.speakText(
      'Excellent ! Je suis maintenant configur√© et pr√™t. '
      'Pour me r√©veiller, dites simplement "Hey Ric". '
      'Bienvenue dans votre exp√©rience vocale personnalis√©e !',
    );

    await _markOnboardingCompleted();
  }

  /// Sauvegarder choix personnalit√©
  Future<void> _savePersonalityChoice(String personality) async {
    try {
      final prefs = await SharedPreferences.getInstance();
      await prefs.setString('selected_personality', personality);
      debugPrint('Personnalit√© sauvegard√©e: $personality');
    } catch (e) {
      debugPrint('Erreur sauvegarde personnalit√©: $e');
    }
  }

  /// Marquer onboarding comme termin√©
  Future<void> _markOnboardingCompleted() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      await prefs.setBool('onboarding_completed', true);
      await prefs.setString(
        'onboarding_completion_date',
        DateTime.now().toIso8601String(),
      );

      debugPrint('Onboarding vocal termin√© avec succ√®s');
    } catch (e) {
      debugPrint('Erreur marquage onboarding: $e');
    }
  }

  // Getters
  String get currentStep => _currentStep;
  Map<String, dynamic> get onboardingData => Map.unmodifiable(_onboardingData);
  bool get isInitialized => _isInitialized;

  /// Reset onboarding (pour dev/debug)
  Future<void> resetOnboarding() async {
    final prefs = await SharedPreferences.getInstance();
    await prefs.remove('onboarding_completed');
    await prefs.remove('onboarding_completion_date');
    await prefs.remove('selected_personality');
    _onboardingData.clear();
    _currentStep = 'welcome';
    debugPrint('Onboarding r√©initialis√©');
  }

  // ===============================================
  // M√âTHODES SPATIALES
  // ===============================================

  /// Active le mode spatial pour l'onboarding
  void enableSpatialMode({Function(String)? feedbackCallback}) {
    _spatialModeEnabled = true;
    _spatialFeedbackCallback = feedbackCallback;
    debugPrint('üåå Mode spatial activ√© pour l\'onboarding');
  }

  /// D√©sactive le mode spatial
  void disableSpatialMode() {
    _spatialModeEnabled = false;
    _spatialFeedbackCallback = null;
    debugPrint('üåå Mode spatial d√©sactiv√©');
  }

  /// Envoie un feedback spatial si le mode est activ√©
  void _sendSpatialFeedback(String message) {
    if (_spatialModeEnabled && _spatialFeedbackCallback != null) {
      _spatialFeedbackCallback!(message);
    }
  }

  /// D√©marre l'onboarding en mode spatial
  Future<void> startSpatialOnboarding() async {
    if (!_isInitialized) {
      await initialize();
    }

    _spatialModeEnabled = true;

    try {
      final isFirstRun = await _isFirstRun();

      _sendSpatialFeedback('Initialisation de l\'univers spatial...');

      if (isFirstRun) {
        await _stepSpatialWelcomeFirstTime();
      } else {
        await _stepSpatialWelcomeReturning();
      }
    } catch (e) {
      debugPrint('Erreur onboarding spatial: $e');
      _sendSpatialFeedback('Erreur lors de l\'initialisation');
      await _markOnboardingCompleted();
    }
  }

  /// √âtape spatiale : Accueil premi√®re fois
  Future<void> _stepSpatialWelcomeFirstTime() async {
    _currentStep = 'spatial_welcome_first';

    _sendSpatialFeedback('Bienvenue dans l\'univers HordVoice');

    await _unifiedService.speakText(
      'Bienvenue dans l\'univers HordVoice ! Je suis Ric, votre guide spatial. '
      'Nous allons explorer ensemble les fonctionnalit√©s vocales de cet univers immersif. '
      'Pr√™t pour cette aventure spatiale ?',
    );

    await Future.delayed(Duration(seconds: 2));
    await _stepSpatialMicrophone();
  }

  /// √âtape spatiale : Accueil utilisateur connu
  Future<void> _stepSpatialWelcomeReturning() async {
    _currentStep = 'spatial_welcome_returning';

    _sendSpatialFeedback('Bon retour dans l\'univers spatial');

    await _unifiedService.speakText(
      'Bon retour dans l\'univers HordVoice ! '
      'Vos param√®tres spatiaux sont conserv√©s. Continuons notre exploration.',
    );

    await Future.delayed(Duration(seconds: 1));
    // Aller directement √† la v√©rification finale en mode retour
    await _stepSpatialCompletion();
  }

  /// √âtape spatiale : Configuration microphone
  Future<void> _stepSpatialMicrophone() async {
    _currentStep = 'spatial_microphone';

    _sendSpatialFeedback('Configuration du microphone spatial');

    final micStatus = await Permission.microphone.status;

    if (micStatus.isGranted) {
      await _unifiedService.speakText(
        'Excellent ! Le microphone spatial est d√©j√† configur√©. '
        'Je peux vous entendre parfaitement dans cet univers.',
      );
      await _stepSpatialVoiceDemo();
      return;
    }

    await _unifiedService.speakText(
      'Pour communiquer dans l\'univers spatial, nous devons activer le microphone. '
      'Cela me permettra de percevoir vos commandes vocales √† travers l\'espace. '
      'Autorisons maintenant cette connexion spatiale.',
    );

    await _requestSpatialMicrophonePermission();
  }

  /// Demande permission microphone en mode spatial
  Future<void> _requestSpatialMicrophonePermission() async {
    try {
      _sendSpatialFeedback('Demande d\'autorisation microphone...');

      final result = await Permission.microphone.request();

      if (result.isGranted) {
        await _unifiedService.speakText(
          'Parfait ! La connexion spatiale est √©tablie. '
          'Je peux maintenant vous entendre dans l\'univers.',
        );
        _sendSpatialFeedback('Microphone configur√© avec succ√®s');
        await _stepSpatialVoiceDemo();
      } else {
        await _unifiedService.speakText(
          'Microphone non autoris√©. Nous continuerons en mode visuel pour l\'instant. '
          'Vous pourrez activer la voix plus tard dans les param√®tres spatiaux.',
        );
        _sendSpatialFeedback('Mode visuel activ√©');
        await _stepSpatialCompletion();
      }
    } catch (e) {
      debugPrint('Erreur permission microphone spatial: $e');
      await _stepSpatialCompletion();
    }
  }

  /// √âtape spatiale : D√©monstration vocale
  Future<void> _stepSpatialVoiceDemo() async {
    _currentStep = 'spatial_voice_demo';

    _sendSpatialFeedback('D√©monstration des capacit√©s vocales');

    await _unifiedService.speakText(
      'Testons maintenant nos capacit√©s de communication spatiale. '
      'Dites "Ric, test spatial" et je vous r√©pondrai pour valider la connexion.',
    );

    // Simulation d'√©coute (en production, utiliser le vrai STT)
    _sendSpatialFeedback('√âcoute active...');
    await Future.delayed(Duration(seconds: 4));

    await _unifiedService.speakText(
      'Fantastique ! La communication spatiale fonctionne parfaitement. '
      'Votre voix r√©sonne clairement dans l\'univers HordVoice.',
    );

    _sendSpatialFeedback('Test vocal r√©ussi');
    await _stepSpatialCompletion();
  }

  /// √âtape spatiale : Finalisation
  Future<void> _stepSpatialCompletion() async {
    _currentStep = 'spatial_completion';

    _sendSpatialFeedback('Configuration spatiale termin√©e');

    await _unifiedService.speakText(
      'F√©licitations ! Votre univers HordVoice est maintenant pr√™t. '
      'Vous pouvez explorer toutes les fonctionnalit√©s spatiales et vocales. '
      'Bienvenue dans votre nouvelle dimension interactive !',
    );

    await _markOnboardingCompleted();

    _sendSpatialFeedback('Pr√™t √† explorer l\'univers');

    // Sauvegarder les pr√©f√©rences spatiales
    final prefs = await SharedPreferences.getInstance();
    await prefs.setBool('spatial_mode_preferred', true);
    await prefs.setString(
      'spatial_completion_date',
      DateTime.now().toIso8601String(),
    );
  }

  void dispose() {
    _onboardingData.clear();
    _isInitialized = false;
  }
}
